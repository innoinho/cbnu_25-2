{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d08f1cb3"
      },
      "source": [
        "# 데이터 분석 및 모델링\n",
        "\n",
        "본 노트북은 요기요 리뷰 데이터를 분석하여 고객 요구사항을 식별하고 분류 모델을 구축하는 과정을 담고 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b9c6836"
      },
      "source": [
        "## 0. 필수 라이브러리 설치\n",
        "\n",
        "### Subtask:\n",
        "필요한 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b0b7110"
      },
      "source": [
        "!pip install gensim rake-nltk scikit-learn tensorflow imblearn wordcloud # 필요한 라이브러리 모두 포함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122eb208"
      },
      "source": [
        "## 1. 라이브러리 불러오기\n",
        "\n",
        "### Subtask:\n",
        "분석에 필요한 모든 라이브러리를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ec1274"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, accuracy_score\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import nltk\n",
        "from rake_nltk import Rake\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import matplotlib.font_manager as fm # 폰트 매니저 임포트\n",
        "import os # 폰트 경로 확인 등 필요"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d9ab291"
      },
      "source": [
        "## 2. 데이터 로드\n",
        "\n",
        "### Subtask:\n",
        "원본 데이터인 'yogiyo_reviews_30000.csv' 파일을 로드합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61b20580"
      },
      "source": [
        "**Reasoning**:\n",
        "분석을 위해 원본 데이터 파일을 pandas DataFrame으로 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1fbc1b9"
      },
      "source": [
        "df = pd.read_csv(\"yogiyo_reviews_30000.csv\")\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9195f12"
      },
      "source": [
        "## 3. 사용자 이름 비식별화\n",
        "\n",
        "### Subtask:\n",
        "사용자 이름 열의 개인 정보를 보호하기 위해 블리딩 처리를 수행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "302b1fd8"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to mask user names and apply it to the 'userName' column to create a new 'masked_userName' column. Then, drop the original 'userName' column and display the head of the dataframe to verify the changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0aca802"
      },
      "source": [
        "def mask_username(username):\n",
        "    if isinstance(username, str) and len(username) > 1:\n",
        "        return username[0] + '*' * (len(username) - 1)\n",
        "    return username\n",
        "\n",
        "df['masked_userName'] = df['userName'].apply(mask_username)\n",
        "df = df.drop('userName', axis=1)\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f58c265"
      },
      "source": [
        "## 4. 초기 데이터 전처리\n",
        "\n",
        "### Subtask:\n",
        "리뷰 내용을 토큰화하고 기본적인 전처리를 수행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2b34227"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the tokenize function to remove non-Korean characters and split the text into words. Then, apply this function to the 'content' column and join the tokens back into strings for further processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70b81450"
      },
      "source": [
        "def tokenize(text):\n",
        "    text = re.sub(r\"[^\\uAC00-\\uD7A3\\s]\", \"\", str(text))\n",
        "    return text.split()\n",
        "\n",
        "tokenized_texts = df['content'].apply(tokenize).tolist()\n",
        "texts_joined = [' '.join(tokens) for tokens in tokenized_texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "070e0ec9"
      },
      "source": [
        "## 5. 별점 기반 요구사항 재 라벨링\n",
        "\n",
        "### Subtask:\n",
        "별점을 기준으로 요구사항 라벨을 재설정합니다. (4점 이하 리뷰는 요구사항이 있다고 가정)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ac0ba8"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the user's revised strategy, create a new boolean column 'requirement' where True indicates a score less than or equal to 4, and False otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c186766"
      },
      "source": [
        "df['requirement'] = df['score'] <= 4\n",
        "display(df.head())\n",
        "display(df['requirement'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd47e98f"
      },
      "source": [
        "## 6. 목표 변수 설정\n",
        "\n",
        "### Subtask:\n",
        "감성 라벨과 별점 기반으로 재 라벨링된 요구사항 라벨을 모델의 목표 변수로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f282e26d"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the target variables `y_sentiment` and `y_requirement`. Sentiment is inferred from the score (<= 3 is negative, > 3 is positive). The requirement label is based on the newly created 'requirement' column (True/False converted to 1/0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d09c5eb"
      },
      "source": [
        "# 감성 라벨 (별점 기준 재정의: 3점 이하 negative, 4점 이상 positive)\n",
        "df['sentiment'] = df['score'].apply(lambda x: 0 if x <= 3 else 1)\n",
        "y_sentiment = df['sentiment'].values\n",
        "\n",
        "# 요구사항 라벨 (False/True → 0/1)\n",
        "y_requirement = df['requirement'].astype(int).values\n",
        "\n",
        "print(\"✅ 감성 라벨 분포:\")\n",
        "display(pd.Series(y_sentiment).value_counts())\n",
        "print(\"\\n✅ 요구사항 라벨 분포:\")\n",
        "display(pd.Series(y_requirement).value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22503462"
      },
      "source": [
        "## 7. Word2Vec 임베딩 및 임베딩 행렬 생성\n",
        "\n",
        "### Subtask:\n",
        "전처리된 텍스트 데이터를 사용하여 Word2Vec 모델을 학습시키고 임베딩 행렬을 생성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "241b6090"
      },
      "source": [
        "**Reasoning**:\n",
        "Train a Word2Vec model on the `tokenized_texts` and create an embedding matrix for the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbd1eea5"
      },
      "source": [
        "embedding_dim = 100\n",
        "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=embedding_dim, window=5, min_count=2, workers=2)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts_joined)\n",
        "sequences = tokenizer.texts_to_sequences(texts_joined)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "max_len = 30\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ef3bc55"
      },
      "source": [
        "## 8. 데이터 분할\n",
        "\n",
        "### Subtask:\n",
        "학습 및 평가를 위해 데이터를 분할합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fcd5043"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the data into training and testing sets for both sentiment and requirement labels using `train_test_split`. The test size is set to 20% and a random state is used for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80591aa"
      },
      "source": [
        "X_train, X_test, y_sentiment_train, y_sentiment_test, y_requirement_train, y_requirement_test = train_test_split(\n",
        "    X, y_sentiment, y_requirement, test_size=0.2, random_state=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8652f97f"
      },
      "source": [
        "## 9. 데이터 불균형 해소 (SMOTE 적용)\n",
        "\n",
        "### Subtask:\n",
        "요구사항 분류의 데이터 불균형을 해소하기 위해 SMOTE를 적용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62b2f0f"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply SMOTE to the training data (`X_train`, `y_requirement_train`) to oversample the minority class ('requirement 있음'). This will help address the data imbalance issue and potentially improve the model's performance on the minority class. Note that SMOTE should only be applied to the training data, not the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7cf0f36"
      },
      "source": [
        "# SMOTE 객체 초기화\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# 요구사항 훈련 데이터에 SMOTE 적용\n",
        "# Note: 이 과정에서 X_train과 y_requirement_train의 샘플 수가 증가합니다.\n",
        "# y_sentiment_train은 그대로이므로 다음 모델 학습 단계에서 샘플 수 불일치 오류가 발생할 수 있습니다.\n",
        "X_train_res, y_requirement_train_res = smote.fit_resample(X_train, y_requirement_train)\n",
        "\n",
        "print(\"✅ SMOTE 적용 전 요구사항 훈련 데이터 라벨 분포:\")\n",
        "display(pd.Series(y_requirement_train).value_counts())\n",
        "print(\"\\n✅ SMOTE 적용 후 요구사항 훈련 데이터 라벨 분포:\")\n",
        "display(pd.Series(y_requirement_train_res).value_counts())\n",
        "\n",
        "# Note: y_sentiment_train_res는 SMOTE 적용 결과에 포함되지 않으므로 이 줄은 제거합니다.\n",
        "# print(\"\\n✅ SMOTE 적용 후 감성 훈련 데이터 라벨 분포:\") # 감성 라벨 분포도 확인\n",
        "# display(pd.Series(y_sentiment_train_res).value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b9cd519"
      },
      "source": [
        "## 10. 모델 정의 및 학습 (SMOTE 적용 데이터 활용)\n",
        "\n",
        "### Subtask:\n",
        "재 라벨링된 요구사항 라벨과 SMOTE 적용 데이터를 사용하여 모델을 정의하고 학습합니다. (LSTM 128, Dropout 0.3, Early Stopping 적용)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91840a72"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a neural network model using the Keras functional API with an Embedding layer initialized with the Word2Vec embedding matrix, an LSTM layer, and Dropout. The model has two output layers for sentiment and requirement classification. Compile the model and train it using the training data, including the SMOTE-resampled requirement data, with Early Stopping. Address the sample size mismatch for the sentiment output by aligning it with the resampled data size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a32dec23"
      },
      "source": [
        "# EarlyStopping 콜백 설정\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 모델 구성 (LSTM 128, Dropout 0.3)\n",
        "input_ = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True)(input_)\n",
        "x = LSTM(128, return_sequences=False)(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "out_sentiment = Dense(1, activation='sigmoid', name='sentiment_output')(x)\n",
        "out_requirement = Dense(1, activation='sigmoid', name='requirement_output')(x)\n",
        "\n",
        "model = Model(inputs=input_, outputs=[out_sentiment, out_requirement])\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics={'sentiment_output': 'accuracy', 'requirement_output': 'accuracy'}\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습 (SMOTE 적용된 요구사항 훈련 데이터 사용)\n",
        "# Note: SMOTE만 요구사항 데이터에 적용되었으므로, sentiment는 원본 훈련 데이터 사용\n",
        "# ValueError 해결을 위해 y_sentiment_train의 샘플 수를 X_train_res에 맞춥니다 (데이터 복제 - 이상적이지 않을 수 있음)\n",
        "# 이 부분은 다중 출력 모델과 SMOTE 적용 시 발생할 수 있는 샘플 불일치 문제에 대한 임시 해결책입니다.\n",
        "num_samples_res = X_train_res.shape[0]\n",
        "# Replicate y_sentiment_train to match the number of samples in X_train_res\n",
        "y_sentiment_train_aligned = np.tile(y_sentiment_train, (num_samples_res // y_sentiment_train.shape[0]) + 1)[:num_samples_res]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_res, # SMOTE 적용된 데이터 사용\n",
        "    [y_sentiment_train_aligned, y_requirement_train_res], # sentiment는 샘플 수 맞춤, requirement는 SMOTE 적용 데이터 사용\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1, # 검증 데이터는 SMOTE 적용 전 데이터의 일부에서 분할\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27f9438a"
      },
      "source": [
        "## 11. 모델 평가\n",
        "\n",
        "### Subtask:\n",
        "학습된 모델의 성능을 평가하고 confusion matrix를 시각화합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b87fe72"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained model using the test data and print classification reports for both sentiment and requirement. Visualize the confusion matrices for both tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8416845a"
      },
      "source": [
        "pred_sent, pred_req = model.predict(X_test)\n",
        "pred_sent = (pred_sent > 0.5).astype(int).flatten()\n",
        "pred_req = (pred_req > 0.5).astype(int).flatten()\n",
        "\n",
        "print(\"✅ 감성 분류 평가\")\n",
        "print(classification_report(y_sentiment_test, pred_sent))\n",
        "\n",
        "print(\"\\n✅ 요구사항 분류 평가\")\n",
        "print(classification_report(y_requirement_test, pred_req))\n",
        "\n",
        "cm1 = confusion_matrix(y_sentiment_test, pred_sent)\n",
        "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm1)\n",
        "disp1.plot(cmap='Purples')\n",
        "plt.title(\"Sentiment Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "cm2 = confusion_matrix(y_requirement_test, pred_req)\n",
        "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2)\n",
        "disp2.plot(cmap='Greens')\n",
        "plt.title(\"Requirement Confusion Matrix\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce40634"
      },
      "source": [
        "## 12. 모델 성능 요약표\n",
        "\n",
        "### Subtask:\n",
        "학습된 모델의 감성 및 요구사항 분류 성능 지표를 표로 요약합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29fd3b58"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate or extract the key performance metrics (Precision, Recall, F1-Score, Accuracy) for both sentiment and requirement classification from the test set predictions. Organize these metrics into a pandas DataFrame for a clear and concise summary table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98773990"
      },
      "source": [
        "# 감성 분류 성능 지표 계산\n",
        "sentiment_accuracy = accuracy_score(y_sentiment_test, pred_sent)\n",
        "sentiment_precision = precision_score(y_sentiment_test, pred_sent, average='weighted')\n",
        "sentiment_recall = recall_score(y_sentiment_test, pred_sent, average='weighted')\n",
        "sentiment_f1 = f1_score(y_sentiment_test, pred_sent, average='weighted')\n",
        "\n",
        "# 요구사항 분류 성능 지표 계산\n",
        "requirement_accuracy = accuracy_score(y_requirement_test, pred_req)\n",
        "requirement_precision = precision_score(y_requirement_test, pred_req, average='weighted')\n",
        "requirement_recall = recall_score(y_requirement_test, pred_req, average='weighted')\n",
        "requirement_f1 = f1_score(y_requirement_test, pred_req, average='weighted')\n",
        "\n",
        "# 성능 지표를 DataFrame으로 정리\n",
        "performance_summary = pd.DataFrame({\n",
        "    'Task': ['Sentiment Classification', 'Requirement Classification'],\n",
        "    'Accuracy': [sentiment_accuracy, requirement_accuracy],\n",
        "    'Precision (Weighted)': [sentiment_precision, requirement_precision],\n",
        "    'Recall (Weighted)': [requirement_recall, requirement_recall], # 수정: requirement_recall로 통일\n",
        "    'F1-Score (Weighted)': [sentiment_f1, requirement_f1]\n",
        "})\n",
        "\n",
        "display(performance_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e01b33d"
      },
      "source": [
        "## 13. 모델 학습 과정 시각화\n",
        "\n",
        "### Subtask:\n",
        "모델 학습 중 손실(loss)과 정확도(accuracy) 변화를 시각화합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3720b5f"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract the training and validation loss and accuracy from the `history` object returned by `model.fit`. Plot these values over epochs using Matplotlib to visualize the model's learning progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c748820"
      },
      "source": [
        "# 손실 그래프\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 정확도 그래프 (감성 분류)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['sentiment_output_accuracy'], label='Train Sentiment Accuracy')\n",
        "plt.plot(history.history['val_sentiment_output_accuracy'], label='Validation Sentiment Accuracy')\n",
        "plt.title('Sentiment Classification Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 정확도 그래프 (요구사항 분류)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['requirement_output_accuracy'], label='Train Requirement Accuracy')\n",
        "plt.plot(history.history['val_requirement_output_accuracy'], label='Validation Requirement Accuracy')\n",
        "plt.title('Requirement Classification Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dd5273b"
      },
      "source": [
        "## 14. 요구사항 리뷰 키워드 분석 (RAKE)\n",
        "\n",
        "### Subtask:\n",
        "요구사항이 있다고 판단된 리뷰들을 대상으로 RAKE를 활용하여 핵심 키워드를 추출합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be748bab"
      },
      "source": [
        "**Reasoning**:\n",
        "Use RAKE to extract top keywords from reviews identified as containing requirements based on the re-labeling strategy. Define custom Korean stopwords and apply the RAKE algorithm to the content of the relevant reviews. Display a few examples and save the results to an Excel file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aee88db"
      },
      "source": [
        "# 불용어 오류 방지를 위한 리소스 다운로드\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 1. 요구사항 있는 리뷰만 추출\n",
        "df_req = df[df['requirement'] == True].copy()\n",
        "print(f\"요구사항 포함 리뷰 수: {len(df_req)}\")\n",
        "\n",
        "# 2. 한국어 불용어 수동 지정 (RAKE는 영어 기준 → 한국어 맞춤 대응)\n",
        "korean_stopwords = ['이', '그', '저', '더', '좀', '정말', '진짜', '그리고', '때문에', '것', '수', '있다', '없다', '에서', '입니다']\n",
        "\n",
        "# 3. RAKE 객체 초기화\n",
        "rake = Rake(stopwords=korean_stopwords)\n",
        "\n",
        "# 4. 키워드 추출 함수 정의\n",
        "def extract_keywords_rake(text, top=3):\n",
        "    rake.extract_keywords_from_text(str(text))\n",
        "    return rake.get_ranked_phrases()[:top]\n",
        "\n",
        "# 5. 키워드 추출 적용\n",
        "df_req['keywords'] = df_req['content'].apply(lambda x: extract_keywords_rake(x))\n",
        "\n",
        "# 6. 일부 결과 출력\n",
        "for i in range(min(10, len(df_req))):\n",
        "    print(f\"리뷰: {df_req.iloc[i]['content']}\")\n",
        "    print(f\"핵심 키워드: {df_req.iloc[i]['keywords']}\")\n",
        "    print('-'*60)\n",
        "\n",
        "# 7. 결과를 엑셀로 저장\n",
        "df_req[['content', 'keywords']].to_excel(\"요구사항_리뷰_핵심키워드.xlsx\", index=False)\n",
        "print(\"✅ 결과 저장 완료: '요구사항_리뷰_핵심키워드.xlsx'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbc659d8"
      },
      "source": [
        "## 15. 요구사항 핵심 키워드 워드 클라우드 시각화 (부정 리뷰 기반)\n",
        "\n",
        "### Subtask:\n",
        "부정적인 요구사항 리뷰에서 추출된 핵심 키워드를 워드 클라우드로 시각화합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b1c3b41"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate a word cloud from the extracted keywords specifically from the negative requirement reviews (`df_negative_req`) to visually represent the most frequent and prominent terms in those reviews. This visualization can highlight key areas for improvement for the company by focusing on negative feedback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4316163"
      },
      "source": [
        "# 1. 부정적인 감성이면서 요구사항이 있다고 판단된 리뷰만 추출 (이전 셀에서 생성된 df_negative_req 사용)\n",
        "# df_negative_req = df[(df['sentiment'] == 0) & (df['requirement'] == True)].copy() # 이미 위에서 생성됨\n",
        "\n",
        "# 2. 추출된 키워드 리스트를 하나의 문자열로 합치기 (부정적인 요구사항 리뷰만 사용)\n",
        "all_keywords_negative_req = []\n",
        "# RAKE 객체를 새로 초기화하거나, df_negative_req에 대해 RAKE를 다시 적용해야 합니다.\n",
        "# 여기서는 df_negative_req의 'content' 열에 대해 RAKE를 다시 적용하는 예시 코드를 포함합니다.\n",
        "\n",
        "# RAKE 객체 초기화 (불용어 포함)\n",
        "korean_stopwords = ['이', '그', '저', '더', '좀', '정말', '진짜', '그리고', '때문에', '것', '수', '있다', '없다', '에서', '입니다']\n",
        "rake_neg = Rake(stopwords=korean_stopwords) # 새로운 RAKE 객체 사용\n",
        "\n",
        "# 키워드 추출 함수 정의\n",
        "def extract_keywords_rake_neg(text, top=5): # 상위 키워드 개수를 5개로 늘려보겠습니다.\n",
        "    rake_neg.extract_keywords_from_text(str(text))\n",
        "    return rake_neg.get_ranked_phrases()[:top]\n",
        "\n",
        "# 키워드 추출 적용\n",
        "df_negative_req['keywords_neg'] = df_negative_req['content'].apply(lambda x: extract_keywords_rake_neg(x))\n",
        "\n",
        "\n",
        "for keyword_list in df_negative_req['keywords_neg']:\n",
        "    all_keywords_negative_req.extend(keyword_list)\n",
        "\n",
        "\n",
        "# 3. 키워드 빈도 계산\n",
        "keyword_counts_negative_req = Counter(all_keywords_negative_req)\n",
        "\n",
        "# 4. 한국어 폰트 설정 (Colab 환경에 맞게 수정)\n",
        "# 런타임 다시 시작 후에는 아래 설정만 필요합니다.\n",
        "plt.rc('font', family='NanumGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False # 마이너스 부호 깨짐 방지\n",
        "\n",
        "# 5. 워드 클라우드 생성\n",
        "wordcloud_neg = WordCloud(\n",
        "    font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # 설치된 나눔 폰트 경로\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color='white'\n",
        ").generate_from_frequencies(keyword_counts_negative_req)\n",
        "\n",
        "# 6. 워드 클라우드 시각화\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(wordcloud_neg, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('부정적인 요구사항 리뷰 핵심 키워드 워드 클라우드')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1870a0d8"
      },
      "source": [
        "## 16. 요구사항 핵심 키워드 빈도 막대 그래프 시각화 (부정 리뷰 기반)\n",
        "\n",
        "### Subtask:\n",
        "부정적인 요구사항 리뷰에서 추출된 핵심 키워드의 빈도를 막대 그래프로 시각화합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12e23278"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the frequency of the extracted keywords from the negative requirement reviews (`df_negative_req`). Select the top N most frequent keywords and create a bar chart using Matplotlib to visualize their distribution. This provides a quantitative view of the most pressing issues mentioned in negative requirement reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1504d7d6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.font_manager as fm # 폰트 매니저 임포트\n",
        "\n",
        "# 1. 부정적인 요구사항 리뷰에서 추출된 키워드 리스트 가져오기\n",
        "# 이전 셀에서 df_negative_req와 keyword_counts_negative_req가 생성되었다고 가정합니다.\n",
        "\n",
        "# 2. 키워드 빈도 계산 (이전 셀에서 계산된 keyword_counts_negative_req 사용)\n",
        "# keyword_counts_negative_req = Counter(all_keywords_negative_req) # 이미 계산됨\n",
        "\n",
        "# 3. 상위 N개 키워드 선택\n",
        "top_n = 30 # 원하는 상위 키워드 개수\n",
        "top_keywords_neg = keyword_counts_negative_req.most_common(top_n)\n",
        "top_keywords_dict_neg = dict(top_keywords_neg)\n",
        "\n",
        "# 4. 시각화를 위한 데이터 준비\n",
        "keywords_neg = list(top_keywords_dict_neg.keys())\n",
        "counts_neg = list(top_keywords_dict_neg.values())\n",
        "\n",
        "# 5. 막대 그래프 시각화\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# 한국어 폰트 설정\n",
        "plt.rc('font', family='NanumGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False # 마이너스 부호 깨짐 방지\n",
        "\n",
        "plt.barh(keywords_neg, counts_neg, color='skyblue')\n",
        "plt.xlabel('빈도수')\n",
        "plt.ylabel('핵심 키워드')\n",
        "plt.title(f'부정적인 요구사항 리뷰 상위 {top_n}개 핵심 키워드 빈도')\n",
        "plt.gca().invert_yaxis() # 빈도수 높은 순으로 위에서부터 표시\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}